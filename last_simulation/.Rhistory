ggplot(aes(x = x)) +
theme_light() +
stat_function(fun = truefunc)
failtimes <- c()
for (i in 1:1000) {
hazz <- haz * exp(eta[i])
cumhaz <- cumsum(hazz*0.001)
Surv <- exp(-cumhaz)
failtimes[i] <- tdom[colSums(outer(Surv, u[i], `>`))]
}
hist(failtimes,breaks = 100)
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>=1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
data <- rename(data,exposure = x)
data <- data %>% as_tibble() %>%
mutate(exposure_binned = bin_covariate(exposure,bins = RW2BINS,type = "equal"))
data <- arrange_data(data)
data$ID <- 1:length(u)
Alist <- list()
Alist$exposure <- create_alist_element(data$exposure_binned)
model_data <- list(
A = Alist,
M = Alist %>% map("A") %>% map(ncol) %>% reduce(sum) - 1,
n = length(unique(data$ID)),
X = sparse.model.matrix(eta ~ -1 + poly(exposure,degree = POLYNOMIAL_DEGREE,raw = TRUE),data = data)
)
model_data$theta_logprior <- function(theta,prior_alpha = .85,prior_u = log(20)) {
lambda <- -log(prior_alpha)/prior_u
log(lambda/2) - lambda * exp(-theta/2) - theta/2
}
model_data$beta_logprec <- log(.5)
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$Xd <- model_data$diffmat %*% model_data$X
model_data$p <- ncol(model_data$X)
model_data$Nd <- model_data$n - 1
model_data$Ne <- model_data$n
model_data$Wd <- model_data$M + model_data$p + model_data$Nd
model_data$Wdf <- model_data$M + model_data$p + model_data$Ne
model_data$times <- data$times
model_data$censoring <- data$censoring
model_data$entry <- data$entry
model_data$ID <- data$ID
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$A$exposure$Ad <- model_data$diffmat %*% model_data$A$exposure$A
model_data$Xd <- model_data$diffmat %*% model_data$X
exp(c(-3,1))
1/exp(c(-3,1))
thetagrid <- as.list(seq(-4,1,by = 0.5)) # This is the log(precision)
RW2BINS = 50
length(model_data$censoring==1)
data$censoring
length(data$censoring==1)
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
length(data$censoring==1)
rbinom(n=1,size=1,p=0.65)
rbinom(n=1,size=1,p=0.65)
rbinom(n=1,size=1,p=0.65)
rbinom(n=1,size=1,p=0.65)
rbinom(n=1,size=1,p=0.65)
rbinom(n=1,size=1,p=0.65)
length(data$censoring)
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>=1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
data$censoring
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>=1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
data$censoring[i]
length(data$censoring)
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
length(data$censoring)
failtimes
length(failtimes)
length(failtimes>=1800)
failtimes>=1800
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>=1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
data$censoring
length(data$censoring[data$censoring==1])
length(data$times[data$censoring==1])
length(unique(data$times[data$censoring==1]))
data <- rename(data,exposure = x)
data <- data %>% as_tibble() %>%
mutate(exposure_binned = bin_covariate(exposure,bins = RW2BINS,type = "equal"))
data <- arrange_data(data)
data$ID <- 1:length(u)
Alist <- list()
Alist$exposure <- create_alist_element(data$exposure_binned)
model_data <- list(
A = Alist,
M = Alist %>% map("A") %>% map(ncol) %>% reduce(sum) - 1,
n = length(unique(data$ID)),
X = sparse.model.matrix(eta ~ -1 + poly(exposure,degree = POLYNOMIAL_DEGREE,raw = TRUE),data = data)
)
model_data$theta_logprior <- function(theta,prior_alpha = .85,prior_u = log(20)) {
lambda <- -log(prior_alpha)/prior_u
log(lambda/2) - lambda * exp(-theta/2) - theta/2
}
model_data$beta_logprec <- log(.5)
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$Xd <- model_data$diffmat %*% model_data$X
model_data$p <- ncol(model_data$X)
model_data$Nd <- model_data$n - 1
model_data$Ne <- model_data$n
model_data$Wd <- model_data$M + model_data$p + model_data$Nd
model_data$Wdf <- model_data$M + model_data$p + model_data$Ne
model_data$times <- data$times
model_data$censoring <- data$censoring
model_data$entry <- data$entry
model_data$ID <- data$ID
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$A$exposure$Ad <- model_data$diffmat %*% model_data$A$exposure$A
model_data$Xd <- model_data$diffmat %*% model_data$X
thetagrid <- as.list(seq(-4,1,by = 0.5)) # This is the log(precision)
hessian_log_likelihood(W = model_data$Wd,model_data = model_data)
model_data$Wd
system.time(hessian_log_likelihood(W = rep(0,model_data$Wd),model_data = model_data))
system.time(a <- hessian_log_likelihood(W = rep(0,model_data$Wd),model_data = model_data))
a
hessian_log_likelihood()
hessian_log_likelihood
hessian_log_likelihood
inpara <- function(W,model_data) {
ob <- Get_Observed_index(model_data)
delta <- prep_data_for_log_lik(W,model_data)
#Temporally fill in Delta_11 into delta, to make the future computation easier.
delta <- c(0,delta)
#Define a function to compute one C_i matrix:
GetCi <- function(i,model_data=model_data,delta=delta){
deltavec <- delta[i:model_data$n]
denom <- exp(matrixStats::logSumExp(deltavec[1]-deltavec))
M <- matrix(0,nrow = length(deltavec), ncol = length(deltavec))
for (j in 1:length(deltavec)) {
for (k in j:length(deltavec)) {
if(j==k & k==1){
M[j,k] <- -(exp(matrixStats::logSumExp(deltavec[1]-deltavec))-1)/(denom^2)
}
else if(j==k & k!=1){
deltavec1 <- deltavec[c(-1,-j)]
if(length(deltavec1)==0){
M[j,k] <- -(exp(deltavec[1]-deltavec[j]))/(denom^2)
}
if(length(deltavec1)!=0){
M[j,k] <- -((exp(matrixStats::logSumExp(2*deltavec[1]-deltavec[j]-deltavec1)))+exp(deltavec[1]-deltavec[j]))/(denom^2)
}
}
else if(j==1 & k!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[k]))/(denom^2)
}
else if(k==1 & j!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[j]))/(denom^2)
}
else {
M[j,k]<- (exp(2*deltavec[1]- deltavec[j]-deltavec[k]))/(denom^2)
}
}
}
M <- bdiag(matrix(0,ncol = (model_data$n-ncol(M)),nrow = (model_data$n-nrow(M))),M)
M
}
R <- lapply(ob, GetCi, model_data=model_data,delta=delta)
C_final <- Reduce('+',R)
C_final <- bdiag(C_final[2:nrow(C_final),2:ncol(C_final)],diag(rep(0,model_data$Wd-model_data$Nd),nrow =model_data$Wd-model_data$Nd))
C_final <- as(C_final,"dgCMatrix")
return(-forceSymmetric(C_final))
}
inpara <- function(W,model_data) {
ob <- Get_Observed_index(model_data)
delta <- prep_data_for_log_lik(W,model_data)
#Temporally fill in Delta_11 into delta, to make the future computation easier.
delta <- c(0,delta)
#Define a function to compute one C_i matrix:
GetCi <- function(i,model_data=model_data,delta=delta){
deltavec <- delta[i:model_data$n]
denom <- exp(matrixStats::logSumExp(deltavec[1]-deltavec))
M <- matrix(0,nrow = length(deltavec), ncol = length(deltavec))
for (j in 1:length(deltavec)) {
for (k in j:length(deltavec)) {
if(j==k & k==1){
M[j,k] <- -(exp(matrixStats::logSumExp(deltavec[1]-deltavec))-1)/(denom^2)
}
else if(j==k & k!=1){
deltavec1 <- deltavec[c(-1,-j)]
if(length(deltavec1)==0){
M[j,k] <- -(exp(deltavec[1]-deltavec[j]))/(denom^2)
}
if(length(deltavec1)!=0){
M[j,k] <- -((exp(matrixStats::logSumExp(2*deltavec[1]-deltavec[j]-deltavec1)))+exp(deltavec[1]-deltavec[j]))/(denom^2)
}
}
else if(j==1 & k!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[k]))/(denom^2)
}
else if(k==1 & j!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[j]))/(denom^2)
}
else {
M[j,k]<- (exp(2*deltavec[1]- deltavec[j]-deltavec[k]))/(denom^2)
}
}
}
M <- bdiag(matrix(0,ncol = (model_data$n-ncol(M)),nrow = (model_data$n-nrow(M))),M)
M
}
R <- mclapply(ob, GetCi, model_data=model_data,delta=delta,cores = detectCores())
C_final <- Reduce('+',R)
C_final <- bdiag(C_final[2:nrow(C_final),2:ncol(C_final)],diag(rep(0,model_data$Wd-model_data$Nd),nrow =model_data$Wd-model_data$Nd))
C_final <- as(C_final,"dgCMatrix")
return(-forceSymmetric(C_final))
}
system.time(a <- inpara(W = rep(0,model_data$Wd),model_data = model_data))
system.time(a <- inpara(W = rep(0,model_data$Wd),model_data = model_data))
inpara <- function(W,model_data) {
ob <- Get_Observed_index(model_data)
delta <- prep_data_for_log_lik(W,model_data)
#Temporally fill in Delta_11 into delta, to make the future computation easier.
delta <- c(0,delta)
#Define a function to compute one C_i matrix:
GetCi <- function(i,model_data=model_data,delta=delta){
deltavec <- delta[i:model_data$n]
denom <- exp(matrixStats::logSumExp(deltavec[1]-deltavec))
M <- matrix(0,nrow = length(deltavec), ncol = length(deltavec))
for (j in 1:length(deltavec)) {
for (k in j:length(deltavec)) {
if(j==k & k==1){
M[j,k] <- -(exp(matrixStats::logSumExp(deltavec[1]-deltavec))-1)/(denom^2)
}
else if(j==k & k!=1){
deltavec1 <- deltavec[c(-1,-j)]
if(length(deltavec1)==0){
M[j,k] <- -(exp(deltavec[1]-deltavec[j]))/(denom^2)
}
if(length(deltavec1)!=0){
M[j,k] <- -((exp(matrixStats::logSumExp(2*deltavec[1]-deltavec[j]-deltavec1)))+exp(deltavec[1]-deltavec[j]))/(denom^2)
}
}
else if(j==1 & k!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[k]))/(denom^2)
}
else if(k==1 & j!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[j]))/(denom^2)
}
else {
M[j,k]<- (exp(2*deltavec[1]- deltavec[j]-deltavec[k]))/(denom^2)
}
}
}
M <- bdiag(matrix(0,ncol = (model_data$n-ncol(M)),nrow = (model_data$n-nrow(M))),M)
M
}
R <- mclapply(ob, GetCi, model_data=model_data,delta=delta,cores = detectCores())
C_final <- Reduce('+',R)
C_final <- bdiag(C_final[2:nrow(C_final),2:ncol(C_final)],diag(rep(0,model_data$Wd-model_data$Nd),nrow =model_data$Wd-model_data$Nd))
C_final <- as(C_final,"dgCMatrix")
return(-forceSymmetric(C_final))
}
system.time(a <- inpara(W = rep(0,model_data$Wd),model_data = model_data))
inpara <- function(W,model_data) {
ob <- Get_Observed_index(model_data)
delta <- prep_data_for_log_lik(W,model_data)
#Temporally fill in Delta_11 into delta, to make the future computation easier.
delta <- c(0,delta)
#Define a function to compute one C_i matrix:
GetCi <- function(i,model_data=model_data,delta=delta){
deltavec <- delta[i:model_data$n]
denom <- exp(matrixStats::logSumExp(deltavec[1]-deltavec))
M <- matrix(0,nrow = length(deltavec), ncol = length(deltavec))
for (j in 1:length(deltavec)) {
for (k in j:length(deltavec)) {
if(j==k & k==1){
M[j,k] <- -(exp(matrixStats::logSumExp(deltavec[1]-deltavec))-1)/(denom^2)
}
else if(j==k & k!=1){
deltavec1 <- deltavec[c(-1,-j)]
if(length(deltavec1)==0){
M[j,k] <- -(exp(deltavec[1]-deltavec[j]))/(denom^2)
}
if(length(deltavec1)!=0){
M[j,k] <- -((exp(matrixStats::logSumExp(2*deltavec[1]-deltavec[j]-deltavec1)))+exp(deltavec[1]-deltavec[j]))/(denom^2)
}
}
else if(j==1 & k!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[k]))/(denom^2)
}
else if(k==1 & j!=1){
M[j,k] <- (exp(deltavec[1]-deltavec[j]))/(denom^2)
}
else {
M[j,k]<- (exp(2*deltavec[1]- deltavec[j]-deltavec[k]))/(denom^2)
}
}
}
M <- bdiag(matrix(0,ncol = (model_data$n-ncol(M)),nrow = (model_data$n-nrow(M))),M)
M
}
R <- mclapply(ob, GetCi, model_data=model_data,delta=delta,mc.cores = detectCores())
C_final <- Reduce('+',R)
C_final <- bdiag(C_final[2:nrow(C_final),2:ncol(C_final)],diag(rep(0,model_data$Wd-model_data$Nd),nrow =model_data$Wd-model_data$Nd))
C_final <- as(C_final,"dgCMatrix")
return(-forceSymmetric(C_final))
}
system.time(a <- inpara(W = rep(0,model_data$Wd),model_data = model_data))
model_data$Wd
set.seed(123)
tdom <- seq(0, 1800, by=0.001)
haz <- rep(0, length(tdom))
cut <- 50
for (i in 1:cut) {
low <- as.numeric(quantile(tdom,(i-1)/cut))
high <- as.numeric(quantile(tdom,(i)/cut))
if(i %% 2 == 1){
haz[tdom<=high & tdom > low] <- 1/900
}
if(i %% 2 == 0){
haz[tdom<=high & tdom > low] <- 1/200
}
}
# generate 800 random samples:
N = 800
RW2BINS = 50
POLYNOMIAL_DEGREE = 1
PARALLEL_EXECUTION = T
u <- runif(800)
x <- seq(from = -20, to = 20, length.out = 800)
eta <- 1/(1+exp(-x)) - 0.5
truefunc <- function(x) 10/(1+exp(-x))
tibble(x = c(-10,10)) %>%
ggplot(aes(x = x)) +
theme_light() +
stat_function(fun = truefunc)
failtimes <- c()
for (i in 1:800) {
hazz <- haz * exp(eta[i])
cumhaz <- cumsum(hazz*0.001)
Surv <- exp(-cumhaz)
failtimes[i] <- tdom[colSums(outer(Surv, u[i], `>`))]
}
hist(failtimes,breaks = 100)
x <- seq(from = -20, to = 20, length.out = 800)
eta <- 1/(1+exp(-x)) - 0.5
truefunc <- function(x) 1/(1+exp(-x))
tibble(x = c(-10,10)) %>%
ggplot(aes(x = x)) +
theme_light() +
stat_function(fun = truefunc)
failtimes <- c()
for (i in 1:800) {
hazz <- haz * exp(eta[i])
cumhaz <- cumsum(hazz*0.001)
Surv <- exp(-cumhaz)
failtimes[i] <- tdom[colSums(outer(Surv, u[i], `>`))]
}
hist(failtimes,breaks = 100)
failtimes[model_data$censoring ==1]
failtimes
data <- data_frame(x=x,times = failtimes, entry = rep(0,length(length(u))),censoring = ifelse(failtimes>=1800,yes = 0, no=1))
for (i in 1:length(data$censoring)) {
if(data$censoring[i]==1) data$censoring[i] <- rbinom(n=1,size=1,p=0.65)
}
failtimes[model_data$censoring ==1]
data <- rename(data,exposure = x)
data <- data %>% as_tibble() %>%
mutate(exposure_binned = bin_covariate(exposure,bins = RW2BINS,type = "equal"))
data <- arrange_data(data)
data$ID <- 1:length(u)
Alist <- list()
Alist$exposure <- create_alist_element(data$exposure_binned)
model_data <- list(
A = Alist,
M = Alist %>% map("A") %>% map(ncol) %>% reduce(sum) - 1,
n = length(unique(data$ID)),
X = sparse.model.matrix(eta ~ -1 + poly(exposure,degree = POLYNOMIAL_DEGREE,raw = TRUE),data = data)
)
model_data$theta_logprior <- function(theta,prior_alpha = .85,prior_u = log(20)) {
lambda <- -log(prior_alpha)/prior_u
log(lambda/2) - lambda * exp(-theta/2) - theta/2
}
model_data$beta_logprec <- log(.5)
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$Xd <- model_data$diffmat %*% model_data$X
model_data$p <- ncol(model_data$X)
model_data$Nd <- model_data$n - 1
model_data$Ne <- model_data$n
model_data$Wd <- model_data$M + model_data$p + model_data$Nd
model_data$Wdf <- model_data$M + model_data$p + model_data$Ne
model_data$times <- data$times
model_data$censoring <- data$censoring
model_data$entry <- data$entry
model_data$ID <- data$ID
model_data$diffmat <- create_diff_matrix(model_data$n)
model_data$lambdainv <- create_full_dtcp_matrix(model_data$n)
model_data$A$exposure$Ad <- model_data$diffmat %*% model_data$A$exposure$A
model_data$Xd <- model_data$diffmat %*% model_data$X
thetagrid <- as.list(seq(-4,2,by = 0.5)) # This is the log(precision)
# Random effect model specification data
model_data$modelspec <- model_data$A %>%
purrr::map("model") %>%
purrr::map2(.,names(.),~tibble(covariate = .y,model = .x)) %>%
purrr::reduce(bind_rows)
model_data$vectorofcolumnstoremove <- round(RW2BINS/2)
cat("Finished creating model data!\n")
failtimes[model_data$censoring ==1]
model_data$times[model_data$censoring ==1]
control1 <- list(
prec = 1e-06,
stop.trust.radius = 1e-03,
report.freq = 1,
report.level = 4,
start.trust.radius = 100,
contract.threshold = .25,
contract.factor = .1,
expand.factor = 5,
preconditioner = 1,
trust.iter = 2000000,
cg.tol = 1e-06,
maxit = 1000
)
formula <- inla.surv(times,censoring) ~ -1+exposure + f(exposure_binned,model = 'rw2',constr = T)
Inlaresult <- inla(formula = formula, control.compute = list(dic=TRUE),data = data, family = "coxph",
control.hazard = list(model="rw2",n.intervals = 20),
num.threads = 4)
fhat <- Inlaresult$summary.random$exposure_binned$mean
f.ub <- Inlaresult$summary.random$exposure_binned$`0.975quant`
f.lb <- Inlaresult$summary.random$exposure_binned$`0.025quant`
plotINLA <- data.frame(exposure = Inlaresult$summary.random$exposure_binned$ID)
fit_poly2 <- function(x){
xx <- poly(x,degree = POLYNOMIAL_DEGREE,raw = T)
as.numeric(xx %*% cbind(as.numeric(Inlaresult$summary.fixed[1])))
}
library(trustOptim)
library(INLA)
formula <- inla.surv(times,censoring) ~ -1+exposure + f(exposure_binned,model = 'rw2',constr = T)
Inlaresult <- inla(formula = formula, control.compute = list(dic=TRUE),data = data, family = "coxph",
control.hazard = list(model="rw2",n.intervals = 20),
num.threads = 4)
fhat <- Inlaresult$summary.random$exposure_binned$mean
f.ub <- Inlaresult$summary.random$exposure_binned$`0.975quant`
f.lb <- Inlaresult$summary.random$exposure_binned$`0.025quant`
plotINLA <- data.frame(exposure = Inlaresult$summary.random$exposure_binned$ID)
fit_poly2 <- function(x){
xx <- poly(x,degree = POLYNOMIAL_DEGREE,raw = T)
as.numeric(xx %*% cbind(as.numeric(Inlaresult$summary.fixed[1])))
}
mypoly = fit_poly2(plotINLA$exposure) - fit_poly2(plotINLA$exposure[vv])
meanhere <- fhat-fhat[vv] + mypoly
ggplot(plotINLA, aes(x = exposure)) +
geom_line(aes(y = meanhere)) +
geom_line(aes(y = truefunc(exposure) - truefunc(exposure[vv])),colour = 'blue',linetype = 'solid') +
theme_bw(base_size = 20)
vv <- model_data$vectorofcolumnstoremove
formula <- inla.surv(times,censoring) ~ -1+exposure + f(exposure_binned,model = 'rw2',constr = T)
Inlaresult <- inla(formula = formula, control.compute = list(dic=TRUE),data = data, family = "coxph",
control.hazard = list(model="rw2",n.intervals = 20),
num.threads = 4)
fhat <- Inlaresult$summary.random$exposure_binned$mean
f.ub <- Inlaresult$summary.random$exposure_binned$`0.975quant`
f.lb <- Inlaresult$summary.random$exposure_binned$`0.025quant`
plotINLA <- data.frame(exposure = Inlaresult$summary.random$exposure_binned$ID)
fit_poly2 <- function(x){
xx <- poly(x,degree = POLYNOMIAL_DEGREE,raw = T)
as.numeric(xx %*% cbind(as.numeric(Inlaresult$summary.fixed[1])))
}
mypoly = fit_poly2(plotINLA$exposure) - fit_poly2(plotINLA$exposure[vv])
meanhere <- fhat-fhat[vv] + mypoly
ggplot(plotINLA, aes(x = exposure)) +
geom_line(aes(y = meanhere)) +
geom_line(aes(y = truefunc(exposure) - truefunc(exposure[vv])),colour = 'blue',linetype = 'solid') +
theme_bw(base_size = 20)
control1 <- list(
prec = 1e-06,
stop.trust.radius = 1e-03,
report.freq = 1,
report.level = 4,
start.trust.radius = 100,
contract.threshold = .25,
contract.factor = .1,
expand.factor = 5,
preconditioner = 1,
trust.iter = 2000000,
cg.tol = 1e-06,
maxit = 1000
)
tm <- proc.time()
sim1opt <- optimize_all_thetas_parallel(
theta = thetagrid,
model_data = model_data,
startingvals = rep(0,model_data$Wd),
optcontrol = control1,
doparallel = PARALLEL_EXECUTION
)
rt <- proc.time() - tm
rt
load("~/Desktop/Optim.Rdata")
sim1opt$theta
sim1opt$solution
